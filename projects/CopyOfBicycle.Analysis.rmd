---
title: "Bicycle Analysis"
author: "Kelly Loucks, Sam Giardina, Tucker Southern"
date: "9/19/2017"
output: html_document
---


#Introduction

This is an exploration of bicycle-sharing data in the city of Seattle, WA (USA) from October 2014 - August 2016. I hope to eventually combine this data with other forms of ride-sharing and transportation in the city, but this will be the first step.

Time to get started!

#Loading Necessary Packages

```{r, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE}
# For data manipulation and tidying
library(dplyr)
library(lubridate)
library(tidyr)

# For mapping
library(ggmap)
library(mapproj)

# For data visualizations
library(ggplot2)

# For modeling and machine learning
library(caret)

```

Importing all of the data can be downloaded from Kaggle. This project contains 3 data sets and I’ll import and inspect each data file independently.

```{r}
station <- read.csv(file = "station.csv", header = TRUE, 
                    stringsAsFactors = FALSE)

trip <- read.csv(file = "trip.csv", header = TRUE, 
                 stringsAsFactors = FALSE)

weather <- read.csv(file = "weather.csv", header = TRUE, 
                    stringsAsFactors = FALSE)

```

Ok, let’s take a look at each of these data files.

## Data Structures and Variables
### Station
```{r}
str(station)
```

Looks like this data set is dealing with 9 variables:

* Station ID : The individual ID number for a bike station
* Name : The name of that station ID, also appears to be the rough location of the station
* Latitude : The latitude of the station
* Longitude : The longitude of the station
* Install Date : When that particular station was installed (in MM/DD/YYYY format)
* Install Dock Count : Number of docks (bike positions) available at each station on installation day
* Modification Date : When a particular station was modified (in MM/DD/YYYY format)
* Current Dock Count : Number of docks (bike positions) available at each station on August 31, 2016
* Decommission Date : The date that a particular station was put out of service (in MM/DD/YYYY format)

### Trip
```{r}
str(trip)
```

This data set appears to contain 12 variables:

* Trip ID : An identification number assigned to each trip (from one bike station to another)
* Start Time : The time and date that a bike was borrowed from a station (in MM/DD/YYYY HH:MM format)
* Stop Time : The time and date that a bike was returned to a station (in MM/DD/YYYY HH:MM format)
* Bike ID : The identification number for a specific bike
* Trip Duration : Time of trip (measured in seconds)
* From Station Name : The name of the station where the bike was borrowed from
* To Station Name : The name of the station where the bike was returned to
* From Station ID : The ID number of the station where the bike was borrowed from
* To Station ID : The ID number of the station where the bike was returned to
* User Type : Indicates whether the user was a “Member” (i.e., someone with a monthly or annual membership to Pronto!) or a “Short-Term Pass Holder” (i.e., someone who purchased a 24 hour or 3 day pass)
* Gender : The gender of the rider (if known)
* Birth Year : The year that the rider was born

### Weather
```{r}
str(weather)
```

This data set represents quite a bit of weather data in 21 variables.

* Date : The date in MM/DD/YYYY format
* Max Temperature F : The maximum temperature that day (in degrees F)
* Mean Temperature F : The average temperature that day (in degrees F)
* Min Temperature F : The minimum temperature that day (in degrees F)
* Max Dew Point F : The maximum dew point (in degrees F)
* Mean Dew Point F : The average dew point (in degrees F)
* Min Dew Point F : The minimum dew point (in degrees F)
* Max Humidity : The maximum humidity (in %)
* Mean Humidity : The average humidity (in %)
* Min Humidity : The minimum humidity (in %)
* Maximum Sea Level Pressure : The maximum atmospheric pressure at sea level (in inches of mercury)
* Mean Sea Level Pressure : The average atmospheric pressure at sea level (in inches of mercury)
* Min Sea Level Pressure : The minimum atmospheric pressure at sea level (in inches of mercury)
* Max Visibility Miles : The maximum visibility (in miles)
* Mean Visibility Miles : The average visibility (in miles)
* Min Visibility Miles : The minimum visibility (in miles)
* Max Wind Speed MPH : The maximum sustained wind speed (in miles per hour)
* Mean Wind Speed MPH : The average sustained wind speed (in miles per hour)
* Max Gust Speed MPH : The maximum gust wind speed (in miles per hour)
* Precipitation : The amount of precipitation (measured in inches)
* Events : Weather events that occurred that day (e.g., rain, fog, snow, thunderstorm etc.)

#Data Visualizations
##Exploring the Stations Dataset

Since the “Stations” data set was the first one I imported, let’s start with a little exploration there. First of all, how many unique stations are we dealing with?

```{r, message=FALSE}
station %>% summarise(n_distinct(station_id))
```
```{r}
##   n_distinct(station_id)
## 1                     58
```

Wow! 58 different stations! Let’s take a quick peek at where they are located.

```{r, message=FALSE}
station_locs <- station %>% group_by(station_id) %>% select(1:4, -2)
```
```{r, message=FALSE}
# Load the correct map
mymap <- get_map(location = "Seattle", maptype = "roadmap", zoom = 12)

# Plot a single point for each Station ID
ggmap(mymap) + geom_point(aes(x = long, y = lat), data = station_locs, 
                          alpha = 0.7, color = "darkred", size = 2)

```

So it looks like all of the stations are located near the Lower Queen Anne, Belltown, International District, Capitol Hill and University of Washington areas. Let’s take a more zoomed-in look.

```{r, echo = FALSE}
mymap2 <- get_map(location = c(lon = -122.315, lat = 47.63), maptype = "roadmap", zoom = 13)
ggmap(mymap2) + 
  geom_point(aes(x = long, y = lat), data = station_locs, alpha = 0.7, size = 2, col = "darkred")
```

Great! So the locations are pretty well clustered. I wonder what order they were added in.

### Station Installations

First, let’s convert those character-string date objects to actual dates using the `lubridate` package.

```{r}
station$install_date <- mdy(station$install_date)

# How many times were new stations installed?
station %>% summarise(n_distinct(install_date))

##   n_distinct(install_date)
## 1                        9

# How many stations were installed on each date?
station %>% group_by(install_date) %>% summarise(count = n()) %>% 
    arrange(install_date)
```

It looks like the vast majority (86%) of the stations were added on opening day. Let’s see where those original ones were and where the rest were added.



So they added more stations throughout the district that they serve, instead of adding several new stations to a single neighborhood all at once. Good to know.

Now, I wonder how many bikes can be parked at each station (as of August 31,2016)?

```{r}
hist(station$current_dockcount, breaks = "fd",
     freq = NULL, col = "lightblue",
     main = paste("Histogram of Current Dock Count"),
     xlab = "Number of Bikes per Station",
     axes = TRUE, plot = TRUE, labels = FALSE,
     nclass = NULL, warn.unused = TRUE)
```

Well that’s weird, some of the stations have a dock count of 0. I’m assuming they didn’t start that way. Let’s calculate the change in dock count from station installation to August 31, 2016 and plot it on a map.

```{r}
dock_change <- station %>% group_by(station_id) %>% select(station_id, 
    long, lat, ends_with("dockcount")) %>% mutate(dock_change = current_dockcount - 
    install_dockcount)
```

#### Change in Number of Bike Docks Per Station

Any stations with no change in number of docks are not shown here.

```{r}
ggmap(mymap2) + 
  geom_point(aes(x = long, y = lat, size = factor(dock_change), color = factor(dock_change)), 
             data = dock_change, alpha = 0.6)
```

Wow! Looks like quite a few stations took away bike docks and none gained any. Perhaps those stations weren’t being used very frequently. We’ll have to look at that a bit later.

### Current Station Size

I’m going to take one quick look at the current size of each station before moving on to the next data set. Note: I did not include any stations that were closed as of August 31, 2016 in this map

```{r}
ggmap(mymap2) + 
  geom_point(aes(x = long, y = lat, size = factor(current_dockcount), color = factor(current_dockcount)), 
             data = dock_change, alpha = 0.7) 
```

So it looks like the biggest stations tend to be on the outskirts of the rest. Where there are several stations in close proximity, there tend to be fewer bike docks at each station. That makes sense, logically speaking. If you go to a station and there is no bike to rent, you can easily go to another nearby, assuming there is another nearby. In areas where the stations are more secluded, it’s more important that there be bikes and open spaces readily available for users.

Alright, I’m feeling good about exploring this dataset. Time to check out the trip dataset!

## Exploring the trips dataset

It’s been a while since we’ve looked at the trip dataset, so let’s take another peek at it here.

```{r}
glimpse(trip)

# Make the start and stop dates into POSIXct objects
trip_2 <- trip %>% mutate(start_dt = mdy_hm(starttime), stop_dt = mdy_hm(stoptime))

# Recode the dates
trip_2 <- trip_2 %>% mutate(start_date = paste(month(start_dt), 
    day(start_dt), year(start_dt), sep = "/"))
trip_2$start_date <- mdy(trip_2$start_date)

trip_2 <- trip_2 %>% mutate(stop_date = paste(month(stop_dt), 
    day(stop_dt), year(stop_dt), sep = "/"))
trip_2$stop_date <- mdy(trip_2$stop_date)


```

Great, so there are quite a few things that we can potentially look at using this dataset by itself. Let’s start with the number of trips per day since Pronto! began opening bike stations. To do that, we need to recode our start date/times as POSIXct objects. We’ll use the `lubridate` package for this.

Great! Time to visualize the number of rides per day.

```{r}
trip_2 %>% 
  group_by(start_date) %>%
  summarize(N = n()) %>%
  ggplot(aes(x = start_date, y = N)) + 
  geom_line() + 
  labs(x = "Date", y = "Number of trips per day") + 
  theme_bw() + geom_smooth()

```
.
Hmm, grouping by day is a little noisy. Perhaps we should try by month?

### Plotting Trips Per Month (By Season)

First, we need to create a “Year-Month” variable

```{r}
start_date_ym <- trip_2 %>% mutate(ym = paste(year(start_date), 
    month(start_date), sep = "/"), Season= ifelse(ym %in% c("2014/10", "2014/11"), "Fall",
                                           ifelse(ym  %in% c("2014/12", "2015/1", "2015/2"), "Winter",
                                           ifelse(ym %in% c("2015/3", "2015/4", "2015/5"), "Spring", "Summer"))))

```

Now plot. I think I’ll plot this by month but color it by season (where December, January, and February are “winter”, March, April, and May are “spring”, June, July, August are “summer”, and September, October, November are “autumn”)

```{r}
start_date_ym %>% 
  group_by(ym, Season) %>%
  summarize(N = n()) %>%
  ggplot(aes(x = ym, y = N, col = Season)) + 
  geom_point() +
  geom_line(group = 1) + 
  theme_bw()+
  labs(x = "Date", y = "Number of Trips (Per Month)") 
```

Well that intuitively makes sense. The number of trips taken per month increases in the spring, reaches a maximum in the summer, declines through the fall, remains fairly stable in the winter and then repeats.

### Average trip duration

Great! I wonder how the average trip duration fluctuates over this time period.

```{r}
# Convert Trip Duration from Seconds to Minutes
Trip_Duration_Month <- start_date_ym %>% mutate(trip_duration_min = tripduration/60) %>% 
    group_by(ym) %>% select(ym, trip_duration_min) %>% summarise(Avg = mean(trip_duration_min), 
    sd = sd(trip_duration_min)) %>% mutate(se = sd/sqrt(n()), Season= ifelse(ym %in% c("2014/10", "2014/11"), "Fall",
                                           ifelse(ym  %in% c("2014/12", "2015/1", "2015/2"), "Winter",
                                           ifelse(ym %in% c("2015/3", "2015/4", "2015/5"), "Spring", "Summer"))))
```

Now to plot the average trip duration (in minutes) (plus or minus standard error), with colors indicating season.

```{r, fig.align='center'}
ggplot(Trip_Duration_Month, aes(x = ym, y = Avg, col= Season)) + 
  geom_point() +
  geom_line(aes(group = 1)) + 
  geom_errorbar(aes(ymin=Avg-se, ymax=Avg+se))+
  theme_bw()+
  labs(x = "Date", y = "Duration of Average Trip (minutes)") 
```

There’s surprisingly not a huge range in trip durations here.

The little bit of variation here makes logical sense. Longer trips were being taken in the spring and summer months rather than the fall and winter. It’s also notable that the spring and summer of 2016 may have shown fewer trips than the previous year, show a slight increase in average trip length.

### Number of trips by day of week

I wonder if people are using this service to commute to/from work. Let’s look at the number of trips by day of the week.

First, let’s create a Day of the Week variable.

```{r}
trip_2$wd <- wday(trip_2$start_date, label = TRUE)
```

Now to plot the total number of trips by day of the week.



Ok, so there are definitely more trips during the week than on the weekends. I wonder if this varies by season too.

```{r}
start_date_ym$wd <- wday(start_date_ym$start_date, label = TRUE)
```
```{r}
start_date_ym %>%
  group_by(Season, wd) %>%
  summarize(N = n()) %>%
  ggplot(aes(x = wd, y = N, col = Season, fill=Season, group=Season)) +
  geom_point() +
  geom_line() +
  theme_bw()+
  labs(x = "Day of the Week", y = "Number of Trips")


```

So it looks like usage is relatively consistent across seasons, at least as far as the number of trips are concerned.

### Number of Trips by Time of Day

How about time of day? Are people using these around commuting times during the week and later on weekends?

```{r}
start_date_ym %>%
  group_by(Season, wd, starttime) %>%
  summarize(N = n()) %>%
  ggplot(aes(x = starttime, y = N, col = Season, fill=Season, group=Season)) +
  geom_point() +
  geom_line() +
  theme_bw()+
  labs(x = "Hour of Day", y = "Number of Trips")+
  facet_wrap(~ wd, ncol = 2)
```

Wow, looks like regardless of the season, people are commuting to/from work using this service (there’s a spike between 8 and 10 AM and another between 4 and 7 PM Monday through Friday). But the weekends seem to be popular between 10 AM and 10 PM.

### Trip Duration by Member Type

While it may seem that the trip duration shouldn’t vary widely by member type, a quick look at Pronto!’s pricing structure may make you reconsider that assumption. You see, while you have to purchase either an annual membership ($85/year), a 24-Hour Pass ($8) or a 3-Day Pass ($16) there is still a cap on the duration of your trip. For members, any ride under 45 minutes is free, but any ride going over 45 minutes will incur a fee of $2 for every additional 30 minutes. For short-term users, any ride under 30 minutes is free, but going over that time limit would cost you an additional $2 for the first 30 minutes and $5 for each additional 30 minutes after that!

Let’s see if these time limits cause differing behaviors in our users.

```{r}
trip_2$usertype <- as.factor(trip_2$usertype)
trip_age <- trip_2 %>% mutate(age = year(start_dt) - birthyear)

hist(trip_age$age, main = "Member Age", xlab = "Number of Riders", 
    col = "#56B4E9", breaks = 25)
```






#Trip Routes
```{r}
# Create a dataframe with only station ID, latitude, and
# longitude
station_coord <- station %>% select(station_id, lat, long)

# Trim our trip dataframe to only include start & stop
# dates/times, and station ID
trip_route <- trip_2 %>% select(trip_id, starts_with("start_"), 
    starts_with("stop_"), from_station_id, to_station_id, tripduration)

# Match by station ID
trip_route$start_lat <- station_coord[match(trip_route$from_station_id, 
    station_coord$station_id), "lat"]

trip_route$start_long <- station_coord[match(trip_route$from_station_id, 
    station_coord$station_id), "long"]

trip_route$stop_lat <- station_coord[match(trip_route$to_station_id, 
    station_coord$station_id), "lat"]

trip_route$stop_long <- station_coord[match(trip_route$to_station_id, 
    station_coord$station_id), "long"]


```


#Exploring the weather data set
```{r}
glimpse(weather)


```

#Great, let’s change the Date variable to a POSIXct object, and make the “Events” variable factors.
```{r}
# Adjusting the Date Variable
weather$Date <- mdy(weather$Date)

# Adjusting the Events Variable
weather$Events <- as.factor(weather$Events)


```
#Great. Now how many weather events are there?
```{r}
levels(weather$Events)

```
#wow, so many combinations of rain!
#let's combine a few things that seem to represent the same event 

```{r}
weather$Events <- gsub("Fog , Rain|Fog-Rain", "Fog-Rain", weather$Events)
weather$Events <- gsub("Rain , Snow|Rain-Snow", "Rain-Snow", 
    weather$Events)
weather$Events <- gsub("Rain , Thunderstorm|Rain-Thunderstorm", 
    "Rain-TS", weather$Events)

weather$Events <- as.factor(weather$Events)


```
#look for missing values
```{r}
summary(weather)
```
Ok, so we have one NA for “Mean_Temperature_F”, “Max_Gust_Speed_MPH” seems to be represented as a character vector because it has “-” representing NA values, and we have 361 unlabelled Events.

Max Gust Speed should be the easiest one to fix, so we’ll start there.

```{r}
weather$Max_Gust_Speed_MPH <- gsub("-", 0, weather$Max_Gust_Speed_MPH)

weather$Max_Gust_Speed_MPH <- as.numeric(weather$Max_Gust_Speed_MPH)

```

Great! We changed any absent values for Maximum Gust Speed to 0 MPH and changed the variable type to a number. Uh oh, looks like there are still 185 NA values for Max Gust Speed. That’s a lot to try to replace. I would normally suggest generating a model that could try to predict those values based on other known values, but for now, we’ll just leave it alone.

Since there is only one missing Mean Temperature, it seems the easiest way to fill in the hole is to look up what the average temperature was that day. Note: I certainly would not recommend this if it were any more than one missing value

```{r}
weather[which(is.na(weather$Mean_Temperature_F)), 1]

```
Ok, so we’re looking for the Mean Temperature on February 14, 2016 in the zipcode 98101 (according to dataset documentation). Looks like the mean temperature that day was 50 degrees F.

Time to substitute in that value.

```{r}
weather[490, "Mean_Temperature_F"] <- "50"
```


Perfect. Now what to do with the unlabelled “Event” categories. The dataset “ReadMe” file from Pronto! doesn’t include any information about this weather dataset. The only thing I can think to do is refer to the Event as “Other”.


```{r}
weather$Events <- gsub("^$", "Other", weather$Events)
weather$Events <- as.factor(weather$Events)

```

Ok, we’re in good shape. Now to do a few quick visualizations.
##Temperature
Minimum
```{r}


```
Mean
```{r}


```
Maximum
```{r}


```
Events
```{r}

```
#Combining Weather and Trip Datasets
Good, so we can now see some parts of the weather data. Let’s combine the weather data with our trip data. Let’s try a  left join from the dplyr package.
```{r}
# Make a copy of the data frame
trip_3 <- trip_2

# Change column name in trip_3 to match weather dataset
trip_3$Date <- trip_3$start_date

# Left join the trip and weather dataframes by date.
trip_weather <- left_join(trip_3, weather, by = "Date")

```
#Mean Temperature vs. Number of Trips
Ok. Now let’s see how the number of trips per day is influenced by weather (mean temperature, rounded to the nearest 5 degrees F)

